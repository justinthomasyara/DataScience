{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI3022 F20\n",
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: Justin Yara\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **MIDNIGHT on Friday September 4**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 95 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Problem 4](#p4) |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "\n",
    "### (20 points) Problem 1: Theory (Sampling)\n",
    "***\n",
    "\n",
    "<img style=\"float: left; width: 200px; padding: 3mm;\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/57/Acme_ballot_box_-_Smithsonian.jpg\" alt=\"A ballot box\"/>  \n",
    "You are the head of a news outlet on election day. You have embedded journalists in key U.S. States in order sample voters at different polling stations in the states. Once your journalists choose a polling station, they monitor the station for the election day. The journalists then report back the number of votes for each candidate, which is recorded in a special App on your phone, called Hippocampus. Overall, your team collected data from 6 polling stations in Alaska, 36 polling stations in Ohio, 12 polling stations in Colorado, 6 polling stations in Iowa, and 42 polling stations from California.\n",
    "\n",
    "You want to get a sense of the average amount of votes for each candidate per polling station, so you use the Hippocampus app to randomly choose 1 polling station in Alaska, 6 polling stations in Ohio, 2 polling stations in Colorado, 1 polling station in Iowa, and 7 polling stations from California.\n",
    "\n",
    "$$ \\quad $$\n",
    "    \n",
    "**Part A:** Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution**:\n",
    "- the population: All polling stations\n",
    "- the sample frame: The Hippocampus App with the data from the 6 polling stations in Alaska, 36 polling station in Ohio, 12 polling stations in Colorado, 6 polling stations in Iowa, and 42 polling stations from California.\n",
    "- the sample: 1 polling station in Alaska, 6 polling stations in Ohio, 2 polling stations in Colorado, 1 polling station in Iowa, and 7 polling stations from California.\n",
    "- the type of sample: Stratified sample\n",
    "- the quantity of interest: Average amount of votes cast for each candidate at each polling station\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** You repeat your sampling, again using the Hippocampus app. Now, you order the stations alphabetically by State and choose every 3rd data value. \n",
    "    \n",
    "Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution**:\n",
    "- the population: All polling stations\n",
    "- the sample frame: The Hippocampus App with the data from the 6 polling stations in Alaska, 36 polling station in Ohio, 12 polling stations in Colorado, 6 polling stations in Iowa, and 42 polling stations from California.\n",
    "- the sample: 3rd data value in alphabetically ordered location data \n",
    "- the type of sample: Systematic sample\n",
    "- the quantity of interest: Average amount of votes cast for each candidate at each polling station\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p2'></a>\n",
    "\n",
    "### (20 points) Problem 2: Theory and Computation (Means and Medians)\n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the effect when $y$ changes. To illustrate this, consider the following dataset:\n",
    " \n",
    "$$  4.2 \\quad 5.1 \\quad 5.0 \\quad y \\quad 3.8 \\quad 4.1 \\quad 5.5 \\quad 1.9 $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** Compute the sample mean and sample median for $y=1.5$. Then compute both quantities again for $y=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean with y = 1.5 is:  3.8875\n",
      "The median with y = 1.5 is:  4.15\n",
      "The mean with y = 6 is:  4.45\n",
      "The median with y = 6 is:  4.6\n"
     ]
    }
   ],
   "source": [
    "def addNumbertoList(num):\n",
    "    values = [4.2, 5.1, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    newValues = values.copy()\n",
    "    newValues.append(num)\n",
    "    return newValues\n",
    "\n",
    "print(\"The mean with y = 1.5 is: \", np.mean(addNumbertoList(1.5)))\n",
    "print(\"The median with y = 1.5 is: \", np.median(addNumbertoList(1.5)))\n",
    "print(\"The mean with y = 6 is: \", np.mean(addNumbertoList(6)))\n",
    "print(\"The median with y = 6 is: \", np.median(addNumbertoList(6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Is there a value for $y$ that would make the mean of the data equal to 6? If so, calculate the value of $y$ that makes the mean equal to 6. If not, clearly explain why not.\n",
    "    \n",
    "Is there a value for $y$ that would make the median of the data equal to 6? If so, calculate the values of $y$ that makes the median equal to 6. If not, clearly explain why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution**\n",
    "There is a value for $y$ that makes the mean equal to 6. This value for $y$ is calculated below. It is possible to vary $y$ so that $\\bar{x}_{desired}$ can be any real number.\n",
    "\n",
    "$$ \\bar{x}_{desired} = \\frac{y+ \\sum \\text{rest of list}}{N} $$\n",
    "where N is the number of elements in the data list including $y$. Then $y = N \\cdot \\bar{x}_{desired} - \\sum \\text{rest of list} $. You can let $\\bar{x}_{desired}$ be any real number and calculate $y$ accordingly.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number that will make the mean equal to 6 is:  18.4\n"
     ]
    }
   ],
   "source": [
    "values = [4.2, 5.1, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "sumVals = np.sum(values)\n",
    "N = len(values)+1\n",
    "\n",
    "print(\"The number that will make the mean equal to 6 is: \", (6*N - (sumVals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is **not** however a value for $y$ that will make the median equal to 6. Note the ordered list of data values excluding $y$ below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sorted data values excluding y are: [1.9 3.8 4.1 4.2 5.  5.1 5.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"The sorted data values excluding y are:\",np.sort(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The middle data value is 4.2. If we add a number $y$ such that $4.1 \\leq y \\leq 4.2$, then the median will be an average of $y$ and 4.2, such that $4.1 \\leq \\tilde{x} \\leq 4.2$. \n",
    "\n",
    "Likewise, if we add a number $y$ such that $4.2 \\leq y \\leq 5.0$, the median will be the average of $y$ and 4.2, this time ranging in values from $4.2 \\leq \\tilde{x} \\leq 5.0 $.\n",
    "\n",
    "If we add $y< 4.1$, then $\\tilde{x} = \\frac{4.1+4.2}{2} = 4.15$. \n",
    "\n",
    "And if we add $y > 5.0$, then $\\tilde{x} = \\frac{4.2+5.0}{2} = 4.6$.\n",
    "\n",
    "Thus, the median, $\\tilde{x}$ can never equal 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the sample variance and the sample standard deviation for the original dataset given in part A, with $y=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance with y = 6:  1.4175\n",
      "the std dev with y = 6:  1.1905880899790657\n"
     ]
    }
   ],
   "source": [
    "#Your code for Part C, here# Solution:\n",
    "\n",
    "values_y6 = addNumbertoList(6)\n",
    "print(\"The variance with y = 6: \", np.var(values_y6))\n",
    "print(\"the std dev with y = 6: \", np.std(values_y6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the sample median for the following cases: \n",
    "- $y=5$ \n",
    "- $y=50$ \n",
    "- $y=4.36$ \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to -\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When y is 5, the median is 4.6\n",
      "When y is 50, the median is 4.6\n",
      "When y is 4.36, the median is 4.28\n",
      "When y is inf, the median is 4.6\n",
      "When y is -inf, the median is 4.15\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "yvals = [5,50,4.36,np.Infinity,-np.Infinity]\n",
    "for y in yvals:\n",
    "    x = np.array([y,4.2, 5.1, 5.0, 3.8, 4.1, 5.5, 1.9])\n",
    "    print(\"When y is {}, the median is {}\".format(y,np.median(x)))#Your code for Part D, here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Think about the previous parts, above, and describe in words or mathematical notation the answers to the following two questions:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n",
    "- By varying $y$, what is the set of all the possible values that the sample median could take on? Specifically, for what sets of $y$ values does the median take on its different possible values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "\n",
    "We can push the sample mean around a lot, since we have an equation above that tells us what to set $y$ to for any $\\bar{x}$. So $\\bar{x}$ can be anything. In math, we could write this as $(-\\infty,\\infty)$.\n",
    "\n",
    "The median is different. When $y\\geq 5.0$, the median will be $4.6$.  Similarly, whenever $y \\leq 4.1$, the median will be $4.2$. If $4.1 < y < 5.0$, then the median will be the mean of 4.3 and $y$. Therefore, the median can be $\\{4.28, 4.6,[4.1,5.0]\\}$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Describe in words or mathematical notation, what happens to the sample standard deviation when $y$ is varied in the following ways: \n",
    " \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to \\bar{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "\n",
    "As $y \\to \\infty$, the sample standard deviation $ \\to \\infty $. Since the sample standard deviation involves calculating the squared distance from each data value to the mean, by setting y equal to the mean, the standard deviation will decrease.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p6'></a>\n",
    "\n",
    "## (20 pts) Problem 3: Computation (Scaling)\n",
    "***\n",
    "Consider the following 3 data sets:\n",
    "\n",
    "`A=[0,1,2,3,4,5,6,7,8,9,10,11,12]`\n",
    "\n",
    "`B=[0,0,0,12,7,18,47,25,0,13,0,35]`\n",
    "\n",
    "`C` is the random data set generated by using `np.random.exponential(scale=43, size=1000)`\n",
    "\n",
    "For each data set, perform the following computations in parts A, B, and C:\n",
    "\n",
    "**Part A:** Compute and print the mean and standard deviation of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of A is:  6.0\n",
      "The std of A is:  3.8944404818493075\n",
      "The mean of B is:  13.083333333333334\n",
      "The std of B is:  15.64061341120571\n",
      "The mean of C is:  42.07492854762523\n",
      "The std of C is:  42.11192006645896\n"
     ]
    }
   ],
   "source": [
    "A = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "B = [0,0,0,12,7,18,47,25,0,13,0,35]\n",
    "C = np.random.exponential(scale=43, size=1000)\n",
    "\n",
    "print('The mean of A is: ', np.mean(A))\n",
    "print('The std of A is: ', np.std(A,ddof=1))\n",
    "\n",
    "print('The mean of B is: ', np.mean(B))\n",
    "print('The std of B is: ', np.std(B,ddof=1))\n",
    "\n",
    "print('The mean of C is: ', np.mean(C))\n",
    "print('The std of C is: ', np.std(C,ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of A_new is:  0.0\n",
      "The std of A_new is:  3.8944404818493075\n",
      "The mean of B_new is:  -1.1842378929335002e-15\n",
      "The std of B_new is:  15.64061341120571\n",
      "The mean of C_new is:  1.7621459846850484e-15\n",
      "The std of C_new is:  42.11192006645896\n"
     ]
    }
   ],
   "source": [
    "A_new = [xi-np.mean(A) for xi in A]\n",
    "B_new = [xi-np.mean(B) for xi in B]\n",
    "C_new = [xi-np.mean(C) for xi in C]\n",
    "\n",
    "print('The mean of A_new is: ', np.mean(A_new))\n",
    "print('The std of A_new is: ', np.std(A_new,ddof=1))\n",
    "\n",
    "print('The mean of B_new is: ', np.mean(B_new))\n",
    "print('The std of B_new is: ', np.std(B_new,ddof=1))\n",
    "\n",
    "print('The mean of C_new is: ', np.mean(C_new))\n",
    "print('The std of C_new is: ', np.std(C_new,ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation and then dividing by the original standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of A_newest is:  -5.124106267500723e-17\n",
      "The std of A_newest is:  1.0\n",
      "The mean of B_newest is:  -5.551115123125783e-17\n",
      "The std of B_newest is:  0.9999999999999998\n",
      "The mean of C_newest is:  4.085620730620576e-17\n",
      "The std of C_newest is:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#Solution:\n",
    "\n",
    "A_newest = [xi/np.std(A, ddof=1) for xi in A_new]\n",
    "B_newest = [xi/np.std(B, ddof=1) for xi in B_new]\n",
    "C_newest = [xi/np.std(C, ddof=1) for xi in C_new]\n",
    "\n",
    "print('The mean of A_newest is: ', np.mean(A_newest))\n",
    "print('The std of A_newest is: ', np.std(A_newest,ddof=1))\n",
    "\n",
    "print('The mean of B_newest is: ', np.mean(B_newest))\n",
    "print('The std of B_newest is: ', np.std(B_newest,ddof=1))\n",
    "\n",
    "print('The mean of C_newest is: ', np.mean(C_newest))\n",
    "print('The std of C_newest is: ', np.std(C_newest,ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Why might this result matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "Subtracting the mean and dividing by the standard deviation of the original data set creates a new data set with mean 0 and standard deviation equal to 1. This is how data is standardized and is important when comparing data sets that were recorded using different units. For example, perhaps we wanted to compare daily temperatures for the USA that were recorded in Fahrenheit with daily temperatures in Australia that were recorded in Celsius. Transforming each data set using the previously described method allows for better comparison between the data sets. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Looking at each of the 3 data sets, come up with a real-world context where those kind of numbers might make for reasonable observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "Data in A are a list of small integers: this might be the kind of values we see if we're counting things (number of wins for a sports team, number of students getting specific grade values, etc.).\n",
    "\n",
    "Data in B are mostly small integers, but have a lot of zeros: one common example of data with lots of zeros is precipitation data in the very next problem!  Another example might be feedings times of animals: 0's denote specimens that choose not to eat while the others have times recorded.\n",
    "\n",
    "Data in C are a big collection of numbers from 0 to infinity, which high decimal precision.  We'll learn more applications for exactly those `exponential` points, but one that makes sense is recording times, or weights, or any other physical attribute where we tend to not observe zero or negative values.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p4'></a>\n",
    "\n",
    "## (35 pts) Problem 4: Data (monthly patterns)\n",
    "***\n",
    "\n",
    "NOAA's Physical Sciences division (https://www.esrl.noaa.gov/psd) houses an enormous amount of weather data.  Load `BoulderPrecip.csv` from the course page for the last 120 years of monthly precipitation data from Boulder.  Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../Data/BoulderPrecip.csv does not exist: '../Data/BoulderPrecip.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-787802163d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfPrecip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/BoulderPrecip.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfPrecip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../Data/BoulderPrecip.csv does not exist: '../Data/BoulderPrecip.csv'"
     ]
    }
   ],
   "source": [
    "dfPrecip = pd.read_csv('../Data/BoulderPrecip.csv')\n",
    "dfPrecip.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** SCRUBBING!  Our data set is going to be tough to use for a few reasons.\n",
    "\n",
    "1) When the amount of precipitation was nonzero but too small to be recorded, this data set recorded `tr`.  Replace these with zeroes.\n",
    "\n",
    "2) 2020 isn't over yet!  We have one row at the bottom that isn't fully complete and NA values have been filled into the months that haven't happened yet.  This can wreak havoc on a lot of our methods!  Drop the 2020 data entirely.\n",
    "\n",
    "3) You may have some object typing issues relating to columns that contained both \"Tr\"/\"NA\" and numeric values.  Ensure that Python is treating all of your data as numeric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: using .replace (this is doable with .loc, but harder and may require a loop)\n",
    "df=dfPrecip.replace('Tr', 0.0)\n",
    "df=df.replace(' ', 0)\n",
    "\n",
    "#2: also doable using df.drop\n",
    "df=df[:-2]\n",
    "\n",
    "#3 using an intermediate function and .apply.  There are other ways!\n",
    "def fix_month(val):\n",
    "    num = pd.to_numeric(val)  \n",
    "    return num \n",
    "\n",
    "for columns in df:\n",
    "    df[columns]=df[columns].apply(fix_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Generate a series of 12 box plots with month as the x axis and precipitation on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Easiest way: pandas boxplot\n",
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "df.iloc[:,1:13].boxplot()\n",
    "ax.set_xticklabels(['1','2','3','4','5','6','7','8','9','10','11','12'])\n",
    "ax.set_ylabel(\"Precipitation\")\n",
    "ax.set_title(\"Boulder Monthly Precipitation\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part C:** Spring is the wet season in Boulder.   But what is Spring?\n",
    "\n",
    "Atmospheric scientists love to group months seasonally, breaking the year into a Winter season including December, January, February; a Spring including March, April, and May; and so forth.\n",
    "\n",
    "The solar year, however, says that Spring runs from near the end of March until near the end of June: let's round at the nearest month and say that it includes the months of April, May and June.\n",
    "\n",
    "Generate a box plot with precipitation on the y-axis and the two possible monthly 'Spring' groupings (March-May versus April-June) as the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making new objects:\n",
    "MAM=df['MAR']+df['APR']+df['MAY']\n",
    "AMJ=df['APR']+df['MAY']+df['JUN']\n",
    "\n",
    "# now using mpl boxplot\n",
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "plt.boxplot([MAM,AMJ])\n",
    "ax.set_xticklabels(['MAM','AMJ'])\n",
    "ax.set_ylabel(\"Precipitation\")\n",
    "ax.set_title(\"Boulder Spring Precipitation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** These might look pretty similar!  Highlight and comment on any differences by calculating the mean, standard deviation, and a Tukey five number summary of each classification of Spring.  Is there a reason here to favor one grouping over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AMJ.describe())\n",
    "print([AMJ.mean(), AMJ.std(ddof=1)])\n",
    "\n",
    "print(MAM.describe())\n",
    "print([MAM.mean(), MAM.std(ddof=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "The March-April-May grouping has a higher mean and higher standard deviation: as a whole March is wetter than June but also more volatile.  This increased dispersion is also present in a wider interquartile range.  If we revist the histogram in part C, we should notice both March and June are considerably less wet than April/May in Boulder.  Given this, we could maybe argue that the MAM classification is better just based on the slightly higher average: since April and May are the wettest and most volatile months here, we should probably group the wetter and most volatile of March/June in with them, which would lead to the MAM classification over AMJ.\n",
    "\n",
    "Realistically though, it probably doesn't matter much!  April-May are the true Spring months, at least as measured by precipitation.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Create a density histogram of the September precipitation.  Classify and describe this histogram, including discussion of any skewness, multimodality, or outliers.  Find the data point associated with September, 2013, and recreate your histogram with that value in a different color or otherwise clearly marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make histogram\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "df['SEP'].hist()\n",
    "#find that value\n",
    "lottarain=float(df.loc[df['Year']==2013,'SEP'])\n",
    "ax.axvline(x=lottarain, linestyle='dashed',color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Solution:**\n",
    "This histogram is unimodal and right-skewed, with a single extreme outlier more than 10 inches from the nearest other data value.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
